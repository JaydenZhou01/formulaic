{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import volume\n",
    "import pandas as pd\n",
    "import pickle\n",
    "close_df = pd.read_pickle('/Z1_3500/data/eod/close.pk')\n",
    "volume_df = pd.read_pickle('/Z1_3500/data/eod/volume.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwap_df = (close_df * volume_df).cumsum() / volume_df.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('vwap.pk', 'wb') as f:\n",
    "    pickle.dump(vwap_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2883145/2581389097.py:1: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  return_df = close_df.pct_change().shift(-1)\n"
     ]
    }
   ],
   "source": [
    "# Compute the forward return\n",
    "forward_return_df = close_df.pct_change().shift(-1)\n",
    "with open('../data/return.pk', 'wb') as f:\n",
    "    pickle.dump(forward_return_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'volume.pk'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy open.pk to working directory\n",
    "import shutil\n",
    "shutil.copyfile('/Z1_3500/data/eod/open.pk', 'open.pk')\n",
    "shutil.copyfile('/Z1_3500/data/eod/close.pk', 'close.pk')\n",
    "shutil.copyfile('/Z1_3500/data/eod/high.pk', 'high.pk')\n",
    "shutil.copyfile('/Z1_3500/data/eod/low.pk', 'low.pk')\n",
    "shutil.copyfile('/Z1_3500/data/eod/volume.pk', 'volume.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 09:46:21.481575: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749030381.494487  778357 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749030381.498461  778357 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749030381.510510  778357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749030381.510521  778357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749030381.510523  778357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749030381.510524  778357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-04 09:46:21.514419: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "import os\n",
    "\n",
    "seed = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_iterations = 50\n",
    "batch_size = 64\n",
    "save_every = 1\n",
    "eval_every = 1\n",
    "logdir = '../logs'\n",
    "ckpt_dir = '../checkpoints'\n",
    "os.makedirs(ckpt_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = os.path.join(logdir, \"training.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(logfile),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "writer = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.alpha_pool import AlphaPool\n",
    "from agent.data import DataContainer\n",
    "from agent.environment import AlphaEnv\n",
    "from agent.game import selfplay\n",
    "from agent.network import Network\n",
    "from agent.train import train_network, inference\n",
    "\n",
    "\n",
    "initial_rpns = [\n",
    "        [\"close\", \"dt5\", \"mean\"],\n",
    "        # [\"volume\", \"log\"],\n",
    "        [\"vwap\", \"close\", \"sub\"]\n",
    "    ]\n",
    "stock_data = DataContainer(device=device)\n",
    "pool = AlphaPool(initial_rpns, stock_data)\n",
    "env = AlphaEnv(pool, device, False)\n",
    "net = Network(env.action_size, 128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 04:36:40,881 [INFO] Invalid expression: [BEG, high, -30.0, Mul, high, Add, 0.01, Sub, -10.0, volume, Less, 0.01, Add, 40, Sum, low, high, vwap, 5, Mean]\n",
      "2025-05-30 04:36:40,884 [INFO] Reward: -1.001\n",
      "2025-05-30 04:36:42,732 [INFO] Invalid expression: [BEG, -30.0, open, 1, Max, 1, Median, -0.5, Pow, vwap, volume, close, open, Greater, -0.5, Sub, 20, Median, Greater, Add]\n",
      "2025-05-30 04:36:42,734 [INFO] Reward: -1.001\n",
      "2025-05-30 04:36:48,272 [INFO] Expression: Log(Greater(Greater(Abs(Greater(Div(Add($vwap, 5.0), -1.0), 2.0)), $volume), Add(10.0, Add($open, Greater(10.0, $open)))))\n",
      "2025-05-30 04:36:48,274 [INFO] Reward: 0.02910488028559461\n",
      "2025-05-30 04:36:50,155 [INFO] Invalid expression: [BEG, vwap, close, -10.0, Less, 1, Min, high, 30.0, Div, 5.0, Div, 30.0, Mul, low, volume, 0.01, open, 10.0, vwap]\n",
      "2025-05-30 04:36:50,156 [INFO] Reward: -1.001\n",
      "2025-05-30 04:36:52,105 [INFO] Invalid expression: [BEG, -2.0, volume, Less, Abs, 0.01, close, volume, 2.0, Greater, -5.0, Add, close, 5, Min, Div, 0.01, close, 1, Max]\n",
      "2025-05-30 04:36:52,106 [INFO] Reward: -1.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1 s\n",
      "\n",
      "Total time: 13.3059 s\n",
      "File: /home/jy_zhou/python_project/src/agent/mcts.py\n",
      "Function: mcts_search at line 121\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   121                                           def mcts_search(\n",
      "   122                                                   env: AlphaEnv,\n",
      "   123                                                   eval_func,\n",
      "   124                                                   root_node,\n",
      "   125                                                   c_puct_base,\n",
      "   126                                                   c_puct_init,\n",
      "   127                                                   num_simulations,\n",
      "   128                                                   root_noise,\n",
      "   129                                                   warm_up,\n",
      "   130                                                   deterministic,\n",
      "   131                                           ):\n",
      "   132                                               \n",
      "   133       100          0.0      0.0      0.0      if root_node is None:\n",
      "   134         5          0.0      0.0      0.3          prior_prob, value_logits, value_mean = eval_func(env.observation(), False)\n",
      "   135         5          0.0      0.0      0.0          root_node = Node(num_actions=env.action_size, parent=DummyNode())\n",
      "   136         5          0.0      0.0      0.0          expand(root_node, prior_prob)\n",
      "   137         5          0.0      0.0      0.0          backup(root_node, value_mean)\n",
      "   138                                           \n",
      "   139       100          0.0      0.0      0.0      root_legal_actions = env.legal_actions\n",
      "   140       100          0.0      0.0      0.0      if root_noise:\n",
      "   141       100          0.0      0.0      0.0          add_dirichlet_noise(root_node, root_legal_actions)\n",
      "   142                                               \n",
      "   143       100          0.2      0.0      1.9      sim_env = copy.deepcopy(env)\n",
      "   144       200          0.0      0.0      0.0      env_state = {\"steps\": sim_env.steps,\n",
      "   145       100          0.0      0.0      0.0                   \"state\": sim_env.state,\n",
      "   146       100          0.0      0.0      0.0                   \"tokens\": sim_env._tokens,\n",
      "   147       100          0.0      0.0      0.0                   \"tree\": sim_env._tree}\n",
      "   148                                               \n",
      "   149      5095          0.0      0.0      0.0      while root_node.N < num_simulations:\n",
      "   150      4995          0.0      0.0      0.0          node = root_node\n",
      "   151                                                   \n",
      "   152                                                   # sim_env = copy.deepcopy(env)\n",
      "   153      4995          2.1      0.0     16.0          sim_env.reset_to(copy.deepcopy(env_state))\n",
      "   154                                           \n",
      "   155      4995          0.0      0.0      0.1          obs = sim_env.observation()\n",
      "   156      4995          0.0      0.0      0.0          done = False\n",
      "   157                                           \n",
      "   158                                                   # Selection\n",
      "   159     12836          0.0      0.0      0.0          while node.is_expanded:\n",
      "   160     16642          0.3      0.0      2.5              node = select_child(\n",
      "   161      8321          0.0      0.0      0.0                  node,\n",
      "   162      8321          0.0      0.0      0.0                  sim_env.legal_actions,\n",
      "   163      8321          0.0      0.0      0.0                  c_puct_base,\n",
      "   164      8321          0.0      0.0      0.0                  c_puct_init\n",
      "   165                                                       )\n",
      "   166      8321          4.9      0.0     37.2              obs, reward, done, _, _ = sim_env.step(node.action)\n",
      "   167      8321          0.0      0.0      0.0              if done:\n",
      "   168       480          0.0      0.0      0.0                  break\n",
      "   169                                           \n",
      "   170      4995          0.0      0.0      0.0          if done:\n",
      "   171       480          0.0      0.0      0.0              backup(node, reward)\n",
      "   172       480          0.0      0.0      0.0              continue\n",
      "   173                                           \n",
      "   174                                                   # Expansion\n",
      "   175      4515          0.0      0.0      0.0          obs = sim_env.observation()\n",
      "   176      4515          5.4      0.0     40.8          prior_prob, value_prob, value_mean = eval_func(obs, False)\n",
      "   177      4515          0.0      0.0      0.1          expand(node, prior_prob)\n",
      "   178                                           \n",
      "   179                                                   # Backup\n",
      "   180      4515          0.1      0.0      0.8          backup(node, value_mean)\n",
      "   181                                           \n",
      "   182       100          0.0      0.0      0.0      search_pi = generate_search_policy(root_node.child_N, 1.0 if warm_up else 0.1, root_legal_actions)\n",
      "   183                                           \n",
      "   184       100          0.0      0.0      0.0      action = None\n",
      "   185       100          0.0      0.0      0.0      next_root_node = None\n",
      "   186       100          0.0      0.0      0.0      best_child_Q = 0.0\n",
      "   187                                           \n",
      "   188       100          0.0      0.0      0.0      if deterministic:\n",
      "   189                                                   action = int(np.argmax(root_node.child_N))\n",
      "   190                                               else:\n",
      "   191       100          0.0      0.0      0.0          action = int(np.random.choice(root_node.num_actions, p=search_pi))\n",
      "   192                                           \n",
      "   193       100          0.0      0.0      0.0      if action in root_node.children:\n",
      "   194       100          0.0      0.0      0.0          next_root_node = root_node.children[action]\n",
      "   195                                                   \n",
      "   196       100          0.0      0.0      0.0          N, W = copy.copy(next_root_node.N), copy.copy(next_root_node.W)\n",
      "   197       100          0.0      0.0      0.0          next_root_node.parent = DummyNode()\n",
      "   198       100          0.0      0.0      0.0          next_root_node.N, next_root_node.W = N, W\n",
      "   199       100          0.0      0.0      0.0          next_root_node.action = None\n",
      "   200                                           \n",
      "   201       100          0.0      0.0      0.0          best_child_Q = next_root_node.Q\n",
      "   202                                           \n",
      "   203       100          0.0      0.0      0.0      return (action, search_pi, root_node.Q, best_child_Q, next_root_node)"
     ]
    }
   ],
   "source": [
    "from agent.alpha_pool import AlphaPool\n",
    "from agent.game import selfplay\n",
    "from agent.mcts import mcts_search\n",
    "%lprun -u 1 -f mcts_search selfplay(seed, net, device, env, 50, 1000, 1.0, 5, 5, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mul($open, $open)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent.expression import Div, Greater, Less, Log, Mean, Mul, Pow, RollingOperator, Sub, Var\n",
    "from agent.tokens import ConstantToken, DeltaTimeToken, FeatureToken, FeatureType, OperatorToken\n",
    "from agent.expr_tree import ExprTree\n",
    "# Mul($vwap, Mul(Log($vwap), Mul(-1.0, $vwap)))\n",
    "tree = ExprTree()\n",
    "tree.push(FeatureToken(FeatureType.OPEN))\n",
    "tree.push(FeatureToken(FeatureType.OPEN))\n",
    "tree.push(OperatorToken(Mul))\n",
    "\n",
    "tree.get_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 255.6801,  207.0721,  242.7364,  ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 251.2225,  213.1600,  244.9225,  ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 242.1136,  203.3476,  270.6025,  ...,       nan,       nan,\n",
       "               nan],\n",
       "        ...,\n",
       "        [ 294.4656,  386.1225,  382.9849,  ..., 1814.7599, 2822.7971,\n",
       "         4692.2500],\n",
       "        [ 280.8976,  374.4225,  375.5844,  ..., 1804.5504, 2782.5625,\n",
       "         4622.6396],\n",
       "        [ 284.2596,  366.3396,  382.2025,  ..., 1806.2500, 2798.4102,\n",
       "         4761.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.get_stack().evaluate(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005093226259271706"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.compute_marginal_contribution(tree.get_stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Abs, Log, Add, Sub, Mul, Div, Greater, Less, Pow, Mean, Median, Sum, Std, Var, Max, Min, open, high, low, close, vwap, volume, 1, 5, 10, 20, 40, -30.0, -10.0, -5.0, -2.0, -1.0, -0.5, -0.01, 0.01, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, SEP]\n"
     ]
    }
   ],
   "source": [
    "print(env._actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'state': array([16, 27,  8, 41,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0], dtype=uint8),\n",
       "  'stack_len': 1},\n",
       " 0.009638959290070425,\n",
       " True,\n",
       " False,\n",
       " {'action_masks': array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        dtype=uint8)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(16)\n",
    "env.step(27)\n",
    "env.step(8)\n",
    "env.step(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_rewards = [-0.001, -0.001, -0.001, 0.00963]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = []\n",
    "R = 0.0\n",
    "for r in reversed(step_rewards):\n",
    "    R = r + 0.99 * R\n",
    "    returns.append(R)\n",
    "returns = list(reversed(returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006373879369999998, 0.007448362999999999, 0.008533699999999998, 0.00963]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the buffer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('buffer.pkl', 'wb') as f:\n",
    "    pickle.dump(buffer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the buffer\n",
    "with open('buffer.pkl', 'rb') as f:\n",
    "    buffer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPN: $open\n",
      "Reward: 0.009732796508229941\n",
      "RPN: $low\n",
      "Reward: 0.01375559229602325\n",
      "RPN: $open\n",
      "Reward: 0.009732796508229941\n",
      "RPN: $close\n",
      "Reward: 0.011164936323663877\n",
      "RPN: [SEP, 1.0, volume, -0.01, vwap, -10.0, open, 40, Sum, open, 40, Sum, open, 40, Min]\n",
      "Reward: -5.0\n",
      "Mean Reward: -0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.9911227756727706"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(env, net, device, 5, 100, 1.0, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 09:57:41,034 [INFO] [Train] Epoch 1/30 | Avg Loss: 16.9952\n",
      "2025-05-07 09:57:41,361 [INFO] [Train] Epoch 2/30 | Avg Loss: 9.3666\n",
      "2025-05-07 09:57:41,686 [INFO] [Train] Epoch 3/30 | Avg Loss: 5.7295\n",
      "2025-05-07 09:57:42,018 [INFO] [Train] Epoch 4/30 | Avg Loss: 3.7801\n",
      "2025-05-07 09:57:42,340 [INFO] [Train] Epoch 5/30 | Avg Loss: 3.2504\n",
      "2025-05-07 09:57:42,664 [INFO] [Train] Epoch 6/30 | Avg Loss: 3.1857\n",
      "2025-05-07 09:57:42,989 [INFO] [Train] Epoch 7/30 | Avg Loss: 3.0668\n",
      "2025-05-07 09:57:43,318 [INFO] [Train] Epoch 8/30 | Avg Loss: 2.9407\n",
      "2025-05-07 09:57:43,644 [INFO] [Train] Epoch 9/30 | Avg Loss: 2.8775\n",
      "2025-05-07 09:57:43,965 [INFO] [Train] Epoch 10/30 | Avg Loss: 2.8394\n",
      "2025-05-07 09:57:44,296 [INFO] [Train] Epoch 11/30 | Avg Loss: 2.7630\n",
      "2025-05-07 09:57:44,625 [INFO] [Train] Epoch 12/30 | Avg Loss: 2.7679\n",
      "2025-05-07 09:57:44,948 [INFO] [Train] Epoch 13/30 | Avg Loss: 2.7468\n",
      "2025-05-07 09:57:45,276 [INFO] [Train] Epoch 14/30 | Avg Loss: 2.7200\n",
      "2025-05-07 09:57:45,600 [INFO] [Train] Epoch 15/30 | Avg Loss: 2.6404\n",
      "2025-05-07 09:57:45,927 [INFO] [Train] Epoch 16/30 | Avg Loss: 2.5728\n",
      "2025-05-07 09:57:46,252 [INFO] [Train] Epoch 17/30 | Avg Loss: 2.5735\n",
      "2025-05-07 09:57:46,579 [INFO] [Train] Epoch 18/30 | Avg Loss: 2.4284\n",
      "2025-05-07 09:57:46,899 [INFO] [Train] Epoch 19/30 | Avg Loss: 2.3368\n",
      "2025-05-07 09:57:47,228 [INFO] [Train] Epoch 20/30 | Avg Loss: 2.2528\n",
      "2025-05-07 09:57:47,554 [INFO] [Train] Epoch 21/30 | Avg Loss: 2.2723\n",
      "2025-05-07 09:57:47,883 [INFO] [Train] Epoch 22/30 | Avg Loss: 2.1821\n",
      "2025-05-07 09:57:48,216 [INFO] [Train] Epoch 23/30 | Avg Loss: 2.1871\n",
      "2025-05-07 09:57:48,539 [INFO] [Train] Epoch 24/30 | Avg Loss: 2.1301\n",
      "2025-05-07 09:57:48,871 [INFO] [Train] Epoch 25/30 | Avg Loss: 2.1609\n",
      "2025-05-07 09:57:49,207 [INFO] [Train] Epoch 26/30 | Avg Loss: 2.1283\n",
      "2025-05-07 09:57:49,532 [INFO] [Train] Epoch 27/30 | Avg Loss: 2.1346\n",
      "2025-05-07 09:57:49,852 [INFO] [Train] Epoch 28/30 | Avg Loss: 2.0911\n",
      "2025-05-07 09:57:50,194 [INFO] [Train] Epoch 29/30 | Avg Loss: 2.1024\n",
      "2025-05-07 09:57:50,519 [INFO] [Train] Epoch 30/30 | Avg Loss: 2.1501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "train_network(\n",
    "    net,\n",
    "    buffer,\n",
    "    optimizer,\n",
    "    batch_size,\n",
    "    device=device,\n",
    "    num_epochs=30,\n",
    "    writer=writer,\n",
    "    logger=logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPN: [SEP, volume, -10.0, volume, open, -0.01, low, open, open, open, low, open, open, open, open]\n",
      "Reward: -5.0\n",
      "RPN: [SEP, 0.01, vwap, open, high, volume, open, open, open, open, open, open, open, open, open]\n",
      "Reward: -5.0\n",
      "RPN: [SEP, -10.0, open, volume, 0.5, open, low, open, open, open, open, open, low, open, open]\n",
      "Reward: -5.0\n",
      "RPN: [SEP, low, -2.0, vwap, -30.0, low, open, open, open, open, open, open, low, open, open]\n",
      "Reward: -5.0\n",
      "RPN: [SEP, close, vwap, 0.5, vwap, -5.0, open, open, open, open, open, low, open, open, open]\n",
      "Reward: -5.0\n",
      "Mean Reward: -5.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(env, net, device, 5, 100, 1.0, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
